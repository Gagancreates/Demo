import com.google.cloud.storage.BlobId;
import com.google.cloud.storage.BlobInfo;
import com.google.cloud.storage.Storage;
import com.google.cloud.storage.StorageOptions;
import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;
import org.apache.parquet.avro.AvroParquetWriter;
import org.apache.parquet.hadoop.metadata.CompressionCodecName;

import java.io.ByteArrayOutputStream;
import java.nio.channels.Channels;

public class ParquetToGCS {

    public static void main(String[] args) throws Exception {
        // Define schema
        String schemaString = """
            {
                "type": "record",
                "name": "User",
                "fields": [
                    {"name": "name", "type": "string"},
                    {"name": "age", "type": "int"}
                ]
            }
        """;
        Schema schema = new Schema.Parser().parse(schemaString);

        // Create a generic record
        GenericRecord record1 = new GenericData.Record(schema);
        record1.put("name", "Alice");
        record1.put("age", 30);

        GenericRecord record2 = new GenericData.Record(schema);
        record2.put("name", "Bob");
        record2.put("age", 25);

        // Write to ByteArrayOutputStream
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        try (AvroParquetWriter<GenericRecord> writer = AvroParquetWriter.<GenericRecord>builder(
                new org.apache.parquet.io.OutputStreamOutputFile(outputStream))
                .withSchema(schema)
                .withCompressionCodec(CompressionCodecName.SNAPPY)
                .build()) {
            writer.write(record1);
            writer.write(record2);
        }

        // Upload to GCS
        Storage storage = StorageOptions.getDefaultInstance().getService();
        BlobId blobId = BlobId.of("your-bucket-name", "path/to/file.parquet");
        BlobInfo blobInfo = BlobInfo.newBuilder(blobId).build();
        try (var channel = storage.writer(blobInfo)) {
            channel.write(ByteBuffer.wrap(outputStream.toByteArray()));
        }

        System.out.println("Parquet file uploaded to GCS!");
    }
}
<dependencies>
    <!-- Apache Parquet -->
    <dependency>
        <groupId>org.apache.parquet</groupId>
        <artifactId>parquet-avro</artifactId>
        <version>1.13.0</version>
    </dependency>

    <!-- Google Cloud Storage -->
    <dependency>
        <groupId>com.google.cloud</groupId>
        <artifactId>google-cloud-storage</artifactId>
        <version>2.26.0</version>
    </dependency>

    <!-- Avro for schema -->
    <dependency>
        <groupId>org.apache.avro</groupId>
        <artifactId>avro</artifactId>
        <version>1.11.1</version>
    </dependency>
</dependencies>
